const express = require('express');
const router = express.Router();
const { authenticateToken, isAdmin } = require('./authRoutes');      
const ServerConfig = require('../models/ServerConfig');
const SocialConfig = require('../models/SocialConfig');
const CorsConfig = require('../models/CorsConfig');
const User = require('../models/User');
const { Hospital } = require('../models/hospital');
const pool = require('../config/mysql');
const multer = require('multer');
const mongoose = require('mongoose');
const fs = require('fs');
const path = require('path');
const proj4 = require('proj4');
const turf = require('@turf/turf');

// ëª¨ë“  ê´€ë¦¬ì ë¼ìš°íŠ¸ì— ì¸ì¦ ë° ê´€ë¦¬ì ê¶Œí•œ ê²€ì¦ ë¯¸ë“¤ì›¨ì–´ ì ìš©
router.use(authenticateToken, isAdmin);

// ì„ì‹œ íŒŒì¼ ì €ì¥ ì„¤ì •
const upload = multer({ 
  dest: 'uploads/',
  limits: {
    fileSize: 500 * 1024 * 1024 // 500MB ì œí•œ
  }
});
// ëŒ€ì‹œë³´ë“œ í†µê³„
router.get('/dashboard/stats', async (req, res) => {
  try {
    // ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if (!Hospital) {
      throw new Error('í•„ìš”í•œ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    // ë³‘ì› ì´ ë¬¸ì„œ ìˆ˜
    const totalHospitals = await Hospital.find().countDocuments();

    // ë³‘ì› ìœ í˜•ë³„ ë¶„í¬
    const hospitalsByType = await Hospital.aggregate([
      { $group: { _id: '$clCdNm', count: { $sum: 1 } } },
      { $project: { type: '$_id', count: 1, _id: 0 } }
    ]);

    // ì§€ì—­ë³„ ë¶„í¬
    const hospitalsByRegion = await Hospital.aggregate([
      { $group: { _id: '$sidoCdNm', count: { $sum: 1 } } },
      { $project: { region: '$_id', count: 1, _id: 0 } }
    ]);

    // ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ë³‘ì›
    const recentUpdates = await Hospital.find()
      .sort({ updatedAt: -1 })
      .limit(5)
      .select('yadmNm updatedAt');

    // ë¹ˆ í•„ë“œ í˜„í™©
    const emptyFields = await Hospital.aggregate([
      {
        $project: {
          name: { $ifNull: ['$yadmNm', 1] },
          address: { $ifNull: ['$addr', 1] },
          phone: { $ifNull: ['$telno', 1] },
          type: { $ifNull: ['$clCdNm', 1] },
          location: { $ifNull: ['$XPos', 1] }
        }
      },
      {
        $group: {
          _id: null,
          name: { $sum: '$name' },
          address: { $sum: '$address' },
          phone: { $sum: '$phone' },
          type: { $sum: '$type' },
          location: { $sum: '$location' }
        }
      }
    ]);

    // ë°ì´í„° í’ˆì§ˆ í‰ê°€
    const dataQuality = await Hospital.aggregate([
      {
        $project: {
          complete: {
            $cond: {
              if: {
                $and: [
                  { $ne: ['$yadmNm', null] },
                  { $ne: ['$addr', null] },
                  { $ne: ['$telno', null] },
                  { $ne: ['$clCdNm', null] },
                  { $ne: ['$XPos', null] }
                ]
              },
              then: 1,
              else: 0
            }
          },
          partial: {
            $cond: {
              if: {
                $and: [
                  { $ne: ['$yadmNm', null] },
                  { $ne: ['$addr', null] },
                  { $or: [
                    { $ne: ['$telno', null] },
                    { $ne: ['$clCdNm', null] },
                    { $ne: ['$XPos', null] }
                  ]}
                ]
              },
              then: 1,
              else: 0
            }
          }
        }
      },
      {
        $group: {
          _id: null,
          complete: { $sum: '$complete' },
          partial: { $sum: '$partial' }
        }
      }
    ]);

    // ì»¬ë ‰ì…˜ë³„ í†µê³„
    const collectionStats = {
      hospitals: {
        total: totalHospitals,
        complete: dataQuality[0]?.complete || 0,
        partial: dataQuality[0]?.partial || 0,
        incomplete: totalHospitals - (dataQuality[0]?.complete || 0) - (dataQuality[0]?.partial || 0)
      }
    };

    res.json({
      collectionStats,
      hospitalsByType: hospitalsByType.reduce((acc, curr) => {
        acc[curr.type] = curr.count;
        return acc;
      }, {}),
      hospitalsByRegion: hospitalsByRegion.reduce((acc, curr) => {
        acc[curr.region] = curr.count;
        return acc;
      }, {}),
      recentUpdates,
      emptyFields: emptyFields[0] || {}
    });
  } catch (error) {
    console.error('ëŒ€ì‹œë³´ë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

// ì„œë²„ ì„¤ì • ê´€ë¦¬
router.get('/server-configs', async (req, res) => {
  try {
    const [configs] = await pool.query('SELECT * FROM hospital_server_configs');
    res.json(configs);
  } catch (error) {
    console.error('ì„œë²„ ì„¤ì • ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

router.post('/server-configs', async (req, res) => {
  try {
    const { key_name, value, environment = 'development', description, is_active = 1 } = req.body;
    await pool.query(
      `INSERT INTO hospital_server_configs 
       (key_name, value, environment, description, is_active) 
       VALUES (?, ?, ?, ?, ?)`,
      [key_name, value, environment, description, is_active]
    );
    res.status(201).json({ message: 'ì„¤ì •ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    console.error('ì„œë²„ ì„¤ì • ì¶”ê°€ ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

router.put('/server-configs/:id', async (req, res) => {
  try {
    const { id } = req.params;
    const { key_name, value, environment, description, is_active } = req.body;
    await pool.query(
      `UPDATE hospital_server_configs 
       SET key_name = ?, value = ?, environment = ?, 
           description = ?, is_active = ?
       WHERE id = ?`,
      [key_name, value, environment, description, is_active, id]
    );
    res.json({ message: 'ì„¤ì •ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    console.error('ì„œë²„ ì„¤ì • ìˆ˜ì • ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

router.delete('/server-configs/:id', async (req, res) => {
  try {
    const { id } = req.params;
    await pool.query('DELETE FROM hospital_server_configs WHERE id = ?', [id]);
    res.json({ message: 'ì„¤ì •ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    console.error('ì„œë²„ ì„¤ì • ì‚­ì œ ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

// ì†Œì…œ ë¡œê·¸ì¸ ì„¤ì • ì¡°íšŒ
router.get('/social-configs', async (req, res) => {
  try {
    const [configs] = await pool.query('SELECT * FROM hospital_social_configs');
    res.json(configs);
  } catch (error) {
    console.error('ì†Œì…œ ì„¤ì • ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

// ì†Œì…œ ë¡œê·¸ì¸ ì„¤ì • ì¶”ê°€
router.post('/social-configs', async (req, res) => {
  try {
    const { provider, client_id, client_secret, redirect_uri, environment, is_active } = req.body;
    await pool.query(
      `INSERT INTO hospital_social_configs 
       (provider, client_id, client_secret, redirect_uri, environment, is_active) 
       VALUES (?, ?, ?, ?, ?, ?)`,
      [provider, client_id, client_secret, redirect_uri, environment, is_active]
    );
    res.status(201).json({ message: 'ì„¤ì •ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    console.error('ì†Œì…œ ì„¤ì • ì¶”ê°€ ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

// ì†Œì…œ ë¡œê·¸ì¸ ì„¤ì • ìˆ˜ì •
router.put('/social-configs/:provider', async (req, res) => {
  try {
    const { provider } = req.params;
    const { client_id, client_secret, redirect_uri, environment, is_active } = req.body;
    await pool.query(
      `UPDATE hospital_social_configs 
       SET client_id = ?, client_secret = ?, redirect_uri = ?, 
           environment = ?, is_active = ?
       WHERE provider = ?`,
      [client_id, client_secret, redirect_uri, environment, is_active, provider]
    );
    res.json({ message: 'ì„¤ì •ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    console.error('ì†Œì…œ ì„¤ì • ìˆ˜ì • ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

// ì†Œì…œ ë¡œê·¸ì¸ ì„¤ì • ì‚­ì œ
router.delete('/social-configs/:provider', async (req, res) => {
  try {
    const { provider } = req.params;
    await pool.query('DELETE FROM hospital_social_configs WHERE provider = ?', [provider]);
    res.json({ message: 'ì„¤ì •ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    console.error('ì†Œì…œ ì„¤ì • ì‚­ì œ ì˜¤ë¥˜:', error);
    res.status(500).json({ message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
});

// CORS ì„¤ì • ê´€ë¦¬
router.get('/cors-configs', async (req, res) => {
  try {
    const configs = await CorsConfig.findAll();
    res.json(configs);
  } catch (error) {
    res.status(500).json({ message: 'CORS ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' });
  }
});

router.post('/cors-configs', async (req, res) => {
  try {
    const id = await CorsConfig.create(req.body);
    res.status(201).json({ id });
  } catch (error) {
    res.status(500).json({ message: 'CORS ì„¤ì • ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' });
  }
});

router.put('/cors-configs/:id', async (req, res) => {
  try {
    await CorsConfig.update(req.params.id, req.body);
    res.json({ message: 'CORS ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    res.status(500).json({ message: 'CORS ì„¤ì • ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' });
  }
});

router.delete('/cors-configs/:id', async (req, res) => {
  try {
    await CorsConfig.delete(req.params.id);
    res.json({ message: 'CORS ì„¤ì •ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.' });
  } catch (error) {
    res.status(500).json({ message: 'CORS ì„¤ì • ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' });
  }
});

// GeoJSON íŒŒì¼ ì—…ë¡œë“œ
router.post('/bucket/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤' });
    }

    // íŒŒì¼ ë‚´ìš© í™•ì¸ (GeoJSON í˜•ì‹ ê²€ì¦)
    const fileContent = fs.readFileSync(req.file.path, 'utf8');
    const geoJson = JSON.parse(fileContent);
    
    if (!geoJson.type || !geoJson.features) {
      throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ GeoJSON íŒŒì¼ì…ë‹ˆë‹¤');
    }

    // sggu_boundaries ì»¬ë ‰ì…˜ì— ë°ì´í„° ì €ì¥
    const sgguBoundaries = mongoose.connection.db.collection('sggu_boundaries');
    
    // ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    await sgguBoundaries.deleteMany({});
    
    // ìƒˆë¡œìš´ ë°ì´í„° ì‚½ì…
    const documents = geoJson.features.map(feature => ({
      type: 'Feature',
      properties: feature.properties,
      geometry: feature.geometry,
      createdAt: new Date(),
      updatedAt: new Date()
    }));

    if (documents.length > 0) {
      await sgguBoundaries.insertMany(documents);
    }

    // ì„ì‹œ íŒŒì¼ ì‚­ì œ
    fs.unlinkSync(req.file.path);

    res.json({ 
      message: 'âœ… ì—…ë¡œë“œ ì™„ë£Œ',
      insertedCount: documents.length
    });

  } catch (err) {
    process.stdout.write('\n'); // ì—ëŸ¬ ë°œìƒ ì‹œ ì¤„ë°”ê¿ˆ
    console.error('\nâŒ ì˜¤ë¥˜ ë°œìƒ:');
    console.error('----------------------------------------');
    
    // ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
    const errorMessage = err.message.split('\n')[0]; // ì²« ì¤„ë§Œ ì‚¬ìš©
    console.error(errorMessage);
    
    // ì¢Œí‘œ ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ í‘œì‹œ
    if (errorMessage.includes('longitude/latitude')) {
      const coords = errorMessage.match(/lng: ([\d.]+) lat: ([\d.]+)/);
      if (coords) {
        console.error(`\nì˜ëª»ëœ ì¢Œí‘œê°’: ê²½ë„(${coords[1]}), ìœ„ë„(${coords[2]})`);
        console.error('ì˜¬ë°”ë¥¸ ì¢Œí‘œ ë²”ìœ„: ê²½ë„(-180 ~ 180), ìœ„ë„(-90 ~ 90)');
      }
    }
    
    console.error('----------------------------------------');
    if (err.stack) {
      const stackLines = err.stack.split('\n');
      const relevantStack = stackLines.find(line => line.includes('adminRoutes.js'));
      if (relevantStack) {
        console.error('\nì—ëŸ¬ ìœ„ì¹˜:');
        console.error(relevantStack.trim());
      }
    }
    console.error('\n');
    res.status(500).json({ error: errorMessage });
  }
});

// íŒŒì¼ ëª©ë¡ ì¡°íšŒ API
router.get('/bucket/:type/files', async (req, res) => {
  try {
    const { type } = req.params;
    const { page = 1, limit = 10, search = '', field = '' } = req.query;
    const skip = (parseInt(page) - 1) * parseInt(limit);

    let collection;
    let searchQuery = {};
    
    // ì»¬ë ‰ì…˜ ì„ íƒ
    switch (type) {
      case 'ctp':
        collection = mongoose.connection.db.collection('sggu_boundaries_ctprvn');
        if (search && field) {
          searchQuery[`properties.${field}`] = { $regex: search, $options: 'i' };
        }
        break;
      case 'sig':
        collection = mongoose.connection.db.collection('sggu_boundaries_sig');
        if (search && field) {
          searchQuery[`properties.${field}`] = { $regex: search, $options: 'i' };
        }
        break;
      case 'emd':
        collection = mongoose.connection.db.collection('sggu_boundaries_emd');
        if (search && field) {
          searchQuery[`properties.${field}`] = { $regex: search, $options: 'i' };
        }
        break;
      case 'li':
        collection = mongoose.connection.db.collection('sggu_boundaries_li');
        if (search && field) {
          searchQuery[`properties.${field}`] = { $regex: search, $options: 'i' };
        }
        break;
      default:
        return res.status(400).json({ error: 'ì˜ëª»ëœ ê²½ê³„ íƒ€ì…ì…ë‹ˆë‹¤' });
    }

    // ì „ì²´ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
    const total = await collection.countDocuments(searchQuery);
    
    // í˜ì´ì§€ë„¤ì´ì…˜ëœ ë°ì´í„° ì¡°íšŒ
    const files = await collection
      .find(searchQuery)
      .sort({ 'properties.CTP_KOR_NM': 1 })
      .skip(skip)
      .limit(parseInt(limit))
      .toArray();

    res.json({
      files,
      total,
      page: parseInt(page),
      totalPages: Math.ceil(total / parseInt(limit))
    });
  } catch (err) {
    console.error('íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

// íŒŒì¼ ì‚­ì œ (sggu_boundaries ì»¬ë ‰ì…˜ì˜ ë°ì´í„° ì‚­ì œ)
router.delete('/bucket/files/:fileId', async (req, res) => {
  try {
    const sgguBoundaries = mongoose.connection.db.collection('sggu_boundaries');
    await sgguBoundaries.deleteOne({ _id: new mongoose.Types.ObjectId(req.params.fileId) });
    res.json({ message: 'âœ… ì‚­ì œ ì™„ë£Œ' });
  } catch (err) {
    console.error('âŒ ì‚­ì œ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

// ì‹œë„(CTP) ê²½ê³„ ê´€ë¦¬
router.post('/bucket/ctp/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤' });
    }

    const fileContent = fs.readFileSync(req.file.path, 'utf8');
    const geoJson = JSON.parse(fileContent);
    
    if (!geoJson.type || !geoJson.features) {
      throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ GeoJSON íŒŒì¼ì…ë‹ˆë‹¤');
    }

    console.log('ğŸ” GeoJSON ë°ì´í„° ê²€ì¦ ì™„ë£Œ');
    console.log('ğŸ“Š ì „ì²´ features ìˆ˜:', geoJson.features.length);

    // MongoDB ì—°ê²° í™•ì¸
    if (mongoose.connection.readyState !== 1) {
      throw new Error('MongoDB ì—°ê²°ì´ ë˜ì–´ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.');
    }

    const ctpBoundaries = mongoose.connection.db.collection('sggu_boundaries_ctprvn');
    console.log('ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹œì‘');
    await ctpBoundaries.deleteMany({});
    console.log('ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ');
    
    const features = geoJson.features || [];
    const totalDocs = features.length;
    let insertedCount = 0;

    // 16MB ì œí•œì„ ê³ ë ¤í•œ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
    const MAX_DOC_SIZE = 15 * 1024 * 1024; // 15MB (ì•ˆì „ ë§ˆì§„ í¬í•¨)
    const BATCH_SIZE = 10; // ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
    let currentBatch = [];
    let currentBatchSize = 0;

    console.log('ğŸš€ ë°ì´í„° ì‚½ì… ì‹œì‘');

    for (let i = 0; i < features.length; i++) {
      const feature = features[i];
      if (!feature.properties || !feature.geometry || !feature.geometry.coordinates) {
        console.warn(`âš ï¸ ì˜ëª»ëœ feature ë°œê²¬: ${i + 1}ë²ˆì§¸`);
        continue;
      }
      
      const { CTPRVN_CD, CTP_KOR_NM, CTP_ENG_NM } = feature.properties;
      if (!CTPRVN_CD || !CTP_KOR_NM || !CTP_ENG_NM) {
        console.warn(`âš ï¸ í•„ìˆ˜ ì†ì„± ëˆ„ë½: ${i + 1}ë²ˆì§¸`);
        continue;
      }
      // 1) ì¢Œí‘œ ë³€í™˜(transformCoordinates) í›„ geometry ì¶”ì¶œ
      let geometry = {
        type: feature.geometry.type,
        coordinates: feature.geometry.coordinates.map(polygon => 
          polygon.map(ring => 
            ring.map(coord => {
              const lon = parseFloat(coord[0]);  // xì¶•ì´ ê²½ë„
              const lat = parseFloat(coord[1]);  // yì¶•ì´ ìœ„ë„
              
              if (isNaN(lon) || isNaN(lat) || 
                  lon < -180 || lon > 180 || 
                  lat < -90 || lat > 90) {
                return coord;
              }
              
              return [lon, lat];  // [ê²½ë„, ìœ„ë„] ìˆœì„œë¡œ ì €ì¥
            })
          )
        )
      };

      // 2) turf.cleanCoords ë¡œ ì¤‘ë³µì Â·ë¶ˆí•„ìš” ì  ì œê±°
      const cleaned = turf.cleanCoords({
        type: 'Feature',
        properties: {},
        geometry
      });
      geometry = cleaned.geometry;
     
      const doc = {
        type: 'Feature',
        properties: { CTPRVN_CD, CTP_KOR_NM, CTP_ENG_NM },
        geometry,
        createdAt: new Date(),
        updatedAt: new Date()
      };

      // MongoDB ì§€ë¦¬ê³µê°„ ì¸ë±ìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ë°ì´í„° ì •ë¦¬
      const cleanDoc = {
        type: 'Feature',
        properties: doc.properties,
        geometry: doc.geometry,
        createdAt: doc.createdAt,
        updatedAt: doc.updatedAt
      };

      const docSize = JSON.stringify(cleanDoc).length;
      console.log(`ğŸ“ ë¬¸ì„œ í¬ê¸°: ${docSize} bytes - ${CTP_KOR_NM}`);
      
      // í˜„ì¬ ë°°ì¹˜ì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
      if (currentBatchSize + docSize > MAX_DOC_SIZE || currentBatch.length >= BATCH_SIZE) {
        // í˜„ì¬ ë°°ì¹˜ ì €ì¥
        if (currentBatch.length > 0) {
          try {
            console.log(`ğŸ’¾ ë°°ì¹˜ ì €ì¥ ì‹œì‘: ${currentBatch.length}ê°œ ë¬¸ì„œ`);
            // ê°œë³„ ë¬¸ì„œ ì €ì¥ìœ¼ë¡œ ë³€ê²½
            for (const doc of currentBatch) {
              try {
                await ctpBoundaries.insertOne(doc);
                insertedCount++;
                console.log(`âœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: ${insertedCount}/${totalDocs} - ${doc.properties.CTP_KOR_NM}`);
              } catch (docErr) {
                console.error(`âŒ ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.CTP_KOR_NM}`, docErr);
              }
            }
          } catch (insertErr) {
            console.error(`âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨:`, insertErr);
          }
        }
        // ìƒˆ ë°°ì¹˜ ì‹œì‘
        currentBatch = [doc];
        currentBatchSize = docSize;
      } else {
        // í˜„ì¬ ë°°ì¹˜ì— ì¶”ê°€
        currentBatch.push(doc);
        currentBatchSize += docSize;
      }
    }

    // ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
    if (currentBatch.length > 0) {
      try {
        console.log(`ğŸ’¾ ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ ì‹œì‘: ${currentBatch.length}ê°œ ë¬¸ì„œ`);
        // ê°œë³„ ë¬¸ì„œ ì €ì¥ìœ¼ë¡œ ë³€ê²½
        for (const doc of currentBatch) {
          try {
            await ctpBoundaries.insertOne(doc);
            insertedCount++;
            console.log(`âœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: ${insertedCount}/${totalDocs} - ${doc.properties.CTP_KOR_NM}`);
          } catch (docErr) {
            console.error(`âŒ ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.CTP_KOR_NM}`, docErr);
          }
        }
      } catch (insertErr) {
        console.error(`âŒ ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨:`, insertErr);
      }
    }

    fs.unlinkSync(req.file.path);
    console.log('ğŸ§¹ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ');

    const totalCount = await ctpBoundaries.countDocuments();
    console.log('ğŸ“Š ìµœì¢… ì €ì¥ëœ ë¬¸ì„œ ìˆ˜:', totalCount);

    res.json({ 
      message: 'âœ… ì‹œë„ ê²½ê³„ ì—…ë¡œë“œ ì™„ë£Œ',
      insertedCount,
      totalCount
    });

  } catch (err) {
    console.error('\nâŒ ì˜¤ë¥˜ ë°œìƒ:');
    console.error('----------------------------------------');
    console.error(err.message);
    console.error('----------------------------------------');
    if (err.stack) {
      const stackLines = err.stack.split('\n');
      const relevant = stackLines.find(line => line.includes('adminRoutes.js'));
      if (relevant) {
        console.error('\nì—ëŸ¬ ìœ„ì¹˜:', relevant.trim());
      }
    }
    res.status(500).json({ error: err.message });
  }
});

router.get('/bucket/ctp/files', async (req, res) => {
  try {
    const ctpBoundaries = mongoose.connection.db.collection('sggu_boundaries_ctprvn');
    const files = await ctpBoundaries.find({}).toArray();
    res.json(files);
  } catch (err) {
    console.error('âŒ ì‹œë„ ê²½ê³„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

router.delete('/bucket/ctp/files/:fileId', async (req, res) => {
  try {
    const ctpBoundaries = mongoose.connection.db.collection('sggu_boundaries_ctprvn');
    await ctpBoundaries.deleteOne({ _id: new mongoose.Types.ObjectId(req.params.fileId) });
    res.json({ message: 'âœ… ì‹œë„ ê²½ê³„ ì‚­ì œ ì™„ë£Œ' });
  } catch (err) {
    console.error('âŒ ì‹œë„ ê²½ê³„ ì‚­ì œ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

// ì‹œêµ°êµ¬(SIG) ê²½ê³„ ê´€ë¦¬
router.post('/bucket/sig/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤' });
    }

    const fileContent = fs.readFileSync(req.file.path, 'utf8');
    const geoJson = JSON.parse(fileContent);
    
    if (!geoJson.type || !geoJson.features) {
      throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ GeoJSON íŒŒì¼ì…ë‹ˆë‹¤');
    }

    const sigBoundaries = mongoose.connection.db.collection('sggu_boundaries_sig');
    await sigBoundaries.deleteMany({});
    
    const features = geoJson.features || [];
    const totalDocs = features.length;
    let insertedCount = 0;

    const MAX_DOC_SIZE = 15 * 1024 * 1024;
    const BATCH_SIZE = 10;
    let currentBatch = [];
    let currentBatchSize = 0;

    for (let i = 0; i < features.length; i++) {
      const feature = features[i];
      if (!feature.properties || !feature.geometry || !feature.geometry.coordinates) {
        continue;
      }
      
      const { SIG_CD, SIG_KOR_NM, SIG_ENG_NM } = feature.properties;
      if (!SIG_CD || !SIG_KOR_NM || !SIG_ENG_NM) {
        continue;
      }

      const doc = {
        type: 'Feature',
        properties: { SIG_CD, SIG_KOR_NM, SIG_ENG_NM },
        geometry: {
          type: feature.geometry.type,
          coordinates: feature.geometry.coordinates.map(polygon => 
            polygon.map(ring => 
              ring.map(coord => {
                const lon = parseFloat(coord[0]);  // xì¶•ì´ ê²½ë„
                const lat = parseFloat(coord[1]);  // yì¶•ì´ ìœ„ë„
                
                if (isNaN(lon) || isNaN(lat) || 
                    lon < -180 || lon > 180 || 
                    lat < -90 || lat > 90) {
                  return coord;
                }
                
                return [lon, lat];  // [ê²½ë„, ìœ„ë„] ìˆœì„œë¡œ ì €ì¥
              })
            )
          )
        },
        createdAt: new Date(),
        updatedAt: new Date()
      };

      const cleanDoc = {
        type: 'Feature',
        properties: doc.properties,
        geometry: doc.geometry,
        createdAt: doc.createdAt,
        updatedAt: doc.updatedAt
      };

      const docSize = JSON.stringify(cleanDoc).length;
      
      if (currentBatchSize + docSize > MAX_DOC_SIZE || currentBatch.length >= BATCH_SIZE) {
        if (currentBatch.length > 0) {
          for (const doc of currentBatch) {
            try {
              await sigBoundaries.insertOne(doc);
              insertedCount++;
            } catch (docErr) {
              console.error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.SIG_KOR_NM}`, docErr);
            }
          }
        }
        currentBatch = [doc];
        currentBatchSize = docSize;
      } else {
        currentBatch.push(doc);
        currentBatchSize += docSize;
      }
    }

    if (currentBatch.length > 0) {
      for (const doc of currentBatch) {
        try {
          await sigBoundaries.insertOne(doc);
          insertedCount++;
        } catch (docErr) {
          console.error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.SIG_KOR_NM}`, docErr);
        }
      }
    }

    fs.unlinkSync(req.file.path);
    const totalCount = await sigBoundaries.countDocuments();

    res.json({ 
      message: 'âœ… ì‹œêµ°êµ¬ ê²½ê³„ ì—…ë¡œë“œ ì™„ë£Œ',
      insertedCount,
      totalCount
    });

  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

router.get('/bucket/sig/files', async (req, res) => {
  try {
    const sigBoundaries = mongoose.connection.db.collection('sggu_boundaries_sig');
    const files = await sigBoundaries.find({}).toArray();
    res.json(files);
  } catch (err) {
    console.error('âŒ ì‹œêµ°êµ¬ ê²½ê³„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

router.delete('/bucket/sig/files/:fileId', async (req, res) => {
  try {
    const sigBoundaries = mongoose.connection.db.collection('sggu_boundaries_sig');
    await sigBoundaries.deleteOne({ _id: new mongoose.Types.ObjectId(req.params.fileId) });
    res.json({ message: 'âœ… ì‹œêµ°êµ¬ ê²½ê³„ ì‚­ì œ ì™„ë£Œ' });
  } catch (err) {
    console.error('âŒ ì‹œêµ°êµ¬ ê²½ê³„ ì‚­ì œ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

// ìë©´ë™(EMD) ê²½ê³„ ê´€ë¦¬
router.post('/bucket/emd/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤' });
    }

    const fileContent = fs.readFileSync(req.file.path, 'utf8');
    const geoJson = JSON.parse(fileContent);
    
    if (!geoJson.type || !geoJson.features) {
      throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ GeoJSON íŒŒì¼ì…ë‹ˆë‹¤');
    }

    const emdBoundaries = mongoose.connection.db.collection('sggu_boundaries_emd');
    await emdBoundaries.deleteMany({});
    
    const features = geoJson.features || [];
    const totalDocs = features.length;
    let insertedCount = 0;

    const MAX_DOC_SIZE = 15 * 1024 * 1024;
    const BATCH_SIZE = 10;
    let currentBatch = [];
    let currentBatchSize = 0;

    for (let i = 0; i < features.length; i++) {
      const feature = features[i];
      if (!feature.properties || !feature.geometry || !feature.geometry.coordinates) {
        continue;
      }
      
      const { EMD_CD, EMD_KOR_NM, EMD_ENG_NM } = feature.properties;
      if (!EMD_CD || !EMD_KOR_NM || !EMD_ENG_NM) {
        continue;
      }

      const doc = {
        type: 'Feature',
        properties: { EMD_CD, EMD_KOR_NM, EMD_ENG_NM },
        geometry: {
          type: feature.geometry.type,
          coordinates: feature.geometry.coordinates.map(polygon => 
            polygon.map(ring => 
              ring.map(coord => {
                const lon = parseFloat(coord[0]);  // xì¶•ì´ ê²½ë„
                const lat = parseFloat(coord[1]);  // yì¶•ì´ ìœ„ë„
                
                if (isNaN(lon) || isNaN(lat) || 
                    lon < -180 || lon > 180 || 
                    lat < -90 || lat > 90) {
                  return coord;
                }
                
                return [lon, lat];  // [ê²½ë„, ìœ„ë„] ìˆœì„œë¡œ ì €ì¥
              })
            )
          )
        },
        createdAt: new Date(),
        updatedAt: new Date()
      };

      const cleanDoc = {
        type: 'Feature',
        properties: doc.properties,
        geometry: doc.geometry,
        createdAt: doc.createdAt,
        updatedAt: doc.updatedAt
      };

      const docSize = JSON.stringify(cleanDoc).length;
      
      if (currentBatchSize + docSize > MAX_DOC_SIZE || currentBatch.length >= BATCH_SIZE) {
        if (currentBatch.length > 0) {
          for (const doc of currentBatch) {
            try {
              await emdBoundaries.insertOne(doc);
              insertedCount++;
            } catch (docErr) {
              console.error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.EMD_KOR_NM}`, docErr);
            }
          }
        }
        currentBatch = [doc];
        currentBatchSize = docSize;
      } else {
        currentBatch.push(doc);
        currentBatchSize += docSize;
      }
    }

    if (currentBatch.length > 0) {
      for (const doc of currentBatch) {
        try {
          await emdBoundaries.insertOne(doc);
          insertedCount++;
        } catch (docErr) {
          console.error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.EMD_KOR_NM}`, docErr);
        }
      }
    }

    fs.unlinkSync(req.file.path);
    const totalCount = await emdBoundaries.countDocuments();

    res.json({ 
      message: 'âœ… ìë©´ë™ ê²½ê³„ ì—…ë¡œë“œ ì™„ë£Œ',
      insertedCount,
      totalCount
    });

  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

router.get('/bucket/emd/files', async (req, res) => {
  try {
    const emdBoundaries = mongoose.connection.db.collection('sggu_boundaries_emd');
    const files = await emdBoundaries.find({}).toArray();
    res.json(files);
  } catch (err) {
    console.error('âŒ ìë©´ë™ ê²½ê³„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

router.delete('/bucket/emd/files/:fileId', async (req, res) => {
  try {
    const emdBoundaries = mongoose.connection.db.collection('sggu_boundaries_emd');
    await emdBoundaries.deleteOne({ _id: new mongoose.Types.ObjectId(req.params.fileId) });
    res.json({ message: 'âœ… ìë©´ë™ ê²½ê³„ ì‚­ì œ ì™„ë£Œ' });
  } catch (err) {
    console.error('âŒ ìë©´ë™ ê²½ê³„ ì‚­ì œ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

// ë¦¬(LI) ê²½ê³„ ê´€ë¦¬
router.post('/bucket/li/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤' });
    }

    const fileContent = fs.readFileSync(req.file.path, 'utf8');
    const geoJson = JSON.parse(fileContent);
    
    if (!geoJson.type || !geoJson.features) {
      throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ GeoJSON íŒŒì¼ì…ë‹ˆë‹¤');
    }

    const liBoundaries = mongoose.connection.db.collection('sggu_boundaries_li');
    await liBoundaries.deleteMany({});
    
    const features = geoJson.features || [];
    const totalDocs = features.length;
    let insertedCount = 0;

    const MAX_DOC_SIZE = 15 * 1024 * 1024;
    const BATCH_SIZE = 10;
    let currentBatch = [];
    let currentBatchSize = 0;

    for (let i = 0; i < features.length; i++) {
      const feature = features[i];
      if (!feature.properties || !feature.geometry || !feature.geometry.coordinates) {
        continue;
      }
      
      const { LI_CD, LI_KOR_NM, LI_ENG_NM } = feature.properties;
      if (!LI_CD || !LI_KOR_NM || !LI_ENG_NM) {
        continue;
      }

      const doc = {
        type: 'Feature',
        properties: { LI_CD, LI_KOR_NM, LI_ENG_NM },
        geometry: {
          type: feature.geometry.type,
          coordinates: feature.geometry.coordinates.map(polygon => 
            polygon.map(ring => 
              ring.map(coord => {
                const lon = parseFloat(coord[0]);  // xì¶•ì´ ê²½ë„
                const lat = parseFloat(coord[1]);  // yì¶•ì´ ìœ„ë„
                
                if (isNaN(lon) || isNaN(lat) || 
                    lon < -180 || lon > 180 || 
                    lat < -90 || lat > 90) {
                  return coord;
                }
                
                return [lon, lat];  // [ê²½ë„, ìœ„ë„] ìˆœì„œë¡œ ì €ì¥
              })
            )
          )
        },
        createdAt: new Date(),
        updatedAt: new Date()
      };

      const cleanDoc = {
        type: 'Feature',
        properties: doc.properties,
        geometry: doc.geometry,
        createdAt: doc.createdAt,
        updatedAt: doc.updatedAt
      };

      const docSize = JSON.stringify(cleanDoc).length;
      
      if (currentBatchSize + docSize > MAX_DOC_SIZE || currentBatch.length >= BATCH_SIZE) {
        if (currentBatch.length > 0) {
          for (const doc of currentBatch) {
            try {
              await liBoundaries.insertOne(doc);
              insertedCount++;
            } catch (docErr) {
              console.error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.LI_KOR_NM}`, docErr);
            }
          }
        }
        currentBatch = [doc];
        currentBatchSize = docSize;
      } else {
        currentBatch.push(doc);
        currentBatchSize += docSize;
      }
    }

    if (currentBatch.length > 0) {
      for (const doc of currentBatch) {
        try {
          await liBoundaries.insertOne(doc);
          insertedCount++;
        } catch (docErr) {
          console.error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${doc.properties.LI_KOR_NM}`, docErr);
        }
      }
    }

    fs.unlinkSync(req.file.path);
    const totalCount = await liBoundaries.countDocuments();

    res.json({ 
      message: 'âœ… ë²•ì •ë¦¬ ê²½ê³„ ì—…ë¡œë“œ ì™„ë£Œ',
      insertedCount,
      totalCount
    });

  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

router.get('/bucket/li/files', async (req, res) => {
  try {
    const liBoundaries = mongoose.connection.db.collection('sggu_boundaries_li');
    const files = await liBoundaries.find({}).toArray();
    res.json(files);
  } catch (err) {
    console.error('âŒ ë¦¬ ê²½ê³„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

router.delete('/bucket/li/files/:fileId', async (req, res) => {
  try {
    const liBoundaries = mongoose.connection.db.collection('sggu_boundaries_li');
    await liBoundaries.deleteOne({ _id: new mongoose.Types.ObjectId(req.params.fileId) });
    res.json({ message: 'âœ… ë¦¬ ê²½ê³„ ì‚­ì œ ì™„ë£Œ' });
  } catch (err) {
    console.error('âŒ ë¦¬ ê²½ê³„ ì‚­ì œ ì‹¤íŒ¨:', err);
    res.status(500).json({ error: err.message });
  }
});

module.exports = router; 